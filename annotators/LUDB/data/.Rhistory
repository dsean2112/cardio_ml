predictions <- model(images, training = TRUE)
loss <- loss_object(labels, predictions)
})
gradients <- tape$gradient(loss, model$trainable_variables)
optimizer$apply_gradients(zip_lists(gradients, model$trainable_variables))
train_loss(loss)
train_accuracy(labels, predictions)
}
train <- tf_function(function(train_ds) {
for (batch in train_ds) {
c(images, labels) %<-% batch
train_step(images, labels)
}
})
size(x_train)
x_train
data.frame(x_train)
library(tidyr)
library(ggplot2)
library(keras)
install.packages(tidyr)
library(tidyr)
install.packages(tidyr)
install.packages("tidyr)"
install.packages("tidyr")
library(tidyr)
install.packages("ggplot2")
library(ggplot2)
library(keras)
fashion_mnist <- dataset_fashion_mnist()
reticulate::py_last_error()
fashion_mnist <- dataset_fashion_mnist()
reticulate::py_last_error()
fashion_mnist <- dataset_fashion_mnist()
dataset_fashion_mnist()
dataset_fashion_mnist()
pwd
getwd
getwd()
libpaths()
.libpaths()
.libPaths()
fashion_mnist <- dataset_fashion_mnist()
c(train_images, train_labels) %<-% fashion_mnist$train
c(test_images, test_labels) %<-% fashion_mnist$test
class_names = c('T-shirt/top',
'Trouser',
'Pullover',
'Dress',
'Coat',
'Sandal',
'Shirt',
'Sneaker',
'Bag',
'Ankle boot')
dim(train_images)
dim(train_labels)
train_labels[1:20]
library(tidyr)
library(ggplot2)
image_1 <- as.data.frame(train_images[1, , ])
colnames(image_1) <- seq_len(ncol(image_1))
image_1$y <- seq_len(nrow(image_1))
image_1 <- gather(image_1, "x", "value", -y)
image_1$x <- as.integer(image_1$x)
image_1
ggplot(image_1, aes(x = x, y = y, fill = value)) +
geom_tile() +
scale_fill_gradient(low = "white", high = "black", na.value = NA) +
scale_y_reverse() +
theme_minimal() +
theme(panel.grid = element_blank())   +
theme(aspect.ratio = 1) +
xlab("") +
ylab("")
train_images <- train_images / 255
test_images <- test_images / 255
par(mfcol=c(5,5))
par(mar=c(0, 0, 1.5, 0), xaxs='i', yaxs='i')
for (i in 1:25) {
img <- train_images[i, , ]
img <- t(apply(img, 2, rev))
image(1:28, 1:28, img, col = gray((0:255)/255), xaxt = 'n', yaxt = 'n',
main = paste(class_names[train_labels[i] + 1]))
}
par(mfcol=c(5,5))
par(mar=c(0, 0, 1.5, 0), xaxs='i', yaxs='i')
install.packages(shiva)
install.packages("shiva")
install.packages("shiva")
read_wfdb.r
read_wfdb()
read_wfdb_ds <- function(record,
record_dir = ".",
annotator = NA_character_,
wfdb_path = getOption("wfdb_path"),
begin = 0,
end = NA_integer_,
interval = NA_integer_,
units = "digital",
channels = character(),
...) {
#' @describeIn wfdb_io Reads a multicomponent WFDB-formatted set of files
#'   directly into an `egm` object. This serves to pull together
#'   [read_signal()], [read_header()], and [read_annotation()] for simplicity.
#' @export
# Read signal
sig <- read_signal(
record = record,
record_dir = record_dir,
wfdb_path = wfdb_path,
begin = begin,
end = end,
interval = interval,
units = units,
channels = channels
)
# Read header
hea <- read_header(
record = record,
record_dir = record_dir,
wfdb_path = wfdb_path
)
# Read annotation
if (!is.na(annotator)) {
ann <- read_annotation(
record = record,
record_dir = record_dir,
annotator = annotator,
wfdb_path = wfdb_path
)
} else {
ann <- annotation_table()
}
# Resulting `egm` object
egm(
signal = sig,
header = hea,
annotation = ann
)
}
read_wf
read_wfdb_ds()
getwd()
ls
getwd()
setwd(C:/Users/darre/OneDrive/Documents/UICOM Research/LUDB/data)
setwd("C:/Users/darre/OneDrive/Documents/UICOM Research/LUDB/data")
getwd()
read_wfdb_ds(1.avf)
read_wfdb_ds("1.avf")
ls()
test
read_wfdb_ds(1.avf)
install.packages("remotes")
remotes::install_github("shiva/wfdb.io.R")
remotes::install_github("shiva/wfdb-io.R")
remotes::install_github("shiva/R/wfdb-io.R")
read_signal_ds <- function(record,
record_dir = ".",
wfdb_path = getOption("wfdb_path"),
begin = 0,
end = NA_integer_,
interval = NA_integer_,
units = "digital",
channels = character(),
...) {
#' @describeIn wfdb_io Specifically reads the signal data from the WFDB binary
#'   format, returning a `signal_table` object for evaluation in the R
#'   environment
#'
#' @export
# Validate:
#		WFDB software command
# 	Current or parent working directory
# 	Directory of the record/WFDB files
# 	Variable definitions
rdsamp <- find_wfdb_command("rdsamp")
if (fs::dir_exists(record_dir)) {
wd <- fs::path(record_dir)
} else {
wd <- getwd()
}
checkmate::assert_number(begin)
checkmate::assert_number(end, na.ok = TRUE)
checkmate::assert_number(interval, na.ok = TRUE)
checkmate::assert_choice(units, choices = c("digital", "physical"))
# Create all the necessary parameters for rdsamp
#		-f			Start time
#		-l, -t	Interval length OR end time ... one or other, not both
#		-H			High resolution mode for high-sampling frequencies
#		-p			Uses physical units instead of digital
#							Miliseconds/physical (mV) units
#							default is sample interval (index) and A/D units
# 	-P			Capital P gives back higher number of decimal places
#		-s			Select which signals to print out (can duplicate + re-order)
#							Name or Number, separated by spaces
#							Default prints all signals
#		-v			Column headings
#		-X, -c	Output format: either XML or CSV, default = tab (not needed)
cmd <-
paste(rdsamp, '-r', record) |>
{
\(.) {
if (begin != 0) {
paste(., "-f", begin)
} else {
.
}
}
}() |>
{
\(.) {
if (!is.na(interval)) {
paste(., "-l", interval)
} else {
.
}
}
}() |>
{
\(.) {
if (!is.na(end)) {
paste(., "-t", end)
} else {
.
}
}
}() |>
{
\(.) {
if (units == "physical") {
paste(., "-p")
} else {
.
}
}
}() |>
{
\(.) {
if (length(channels) > 0) {
paste(., "-s", paste(channels, collapse = " "))
} else {
.
}
}
}() |>
paste("-v")
# Temporary local/working directory, to reset at end of function
withr::with_dir(new = wd, code = {
dat <- data.table::fread(cmd = cmd)
})
# Return data after cleaning names
names(dat)[1] <- "sample"
signal_table(dat)
}
getwd
getwd()
read_signal_ds()
find_wfdb_command <- function(.app,
.path = getOption('wfdb_path')) {
cmd <- fs::path(.path, .app)
if (fs::file_exists(cmd)) {
return(cmd)
} else {
warning("Cannot find '", .app, "' in '", .path, "'")
}
}
#' @keywords internal
#' @noRd
annotation_table_to_lines <- function(data) {
# Each annotation file has a string length of 42 characters
# Each annotation `rdann -e` has 4 characters of spaces up front
# When using the `-e` option for rdann, gives an elapsed time
# That assumption leads to spaces before the time starts
# Columns are... n = 6
#		Time
#		Sample
#		Annotation
#		Type
#		Subtype
#		Channel
#		Number
#		Auxillary (7th, ignored)
# The spacing is as such...
# 	[TIME] = 12
# 	[SAMPLE] = 9
# 	[TYPE] = 6
# 	[SUBTYPE] = 5
# 	[CHANNEL] = 5
# 	[NUMBER] = 5
# Each column can get appropriately padded back into lines
v1 <- stringr::str_pad(data[[1]], width = 12, side = "left")
v2 <- stringr::str_pad(data[[2]], width = 9, side = "left")
v3 <- stringr::str_pad(data[[3]], width = 6, side = "left")
v4 <- stringr::str_pad(data[[4]], width = 5, side = "left")
v5 <- stringr::str_pad(data[[5]], width = 5, side = "left")
v6 <- stringr::str_pad(data[[6]], width = 5, side = "left")
# Output will be put back into `wrann` compatible lines
# 	base::sprintf() is 2-3 faster than paste
# 	lines <- paste0(v1, v2, v3, v4, v5, v6)
lines <- sprintf(paste0(rep("%s", 6), collapse = ""), v1, v2, v3, v4, v5, v6)
# Return
lines
}
#' Evaluates a character string and extracts first date and time objects
#' Internally contains different matches for different WFDB formats
#' Requires that string can be broken into components via a space
#' @keywords internal
#' @noRd
parse_date_and_time <- function(x) {
stopifnot('Requires `x` to be a character string' = is.character(x))
# Time
# 	Assumes HH:MM:SS
tm <- stringr::str_extract(x, '\\d\\d:\\d\\d:\\d\\d')
# Dates are more varied
# 	DD/MM/YYYY
dt <- stringr::str_extract(x, '\\d+/\\d+/\\d+')
# Create date time
as.POSIXct(strptime(paste(tm[1], dt[1]), "%H:%M:%S %d/%m/%Y"))
}
read_signal_ds()
read_signal_ds(a)
read_signal_ds(1.avf)
read_signal_ds("1.avf"")
read_signal_ds("1.avf")
cmd()
file(fs::file_exists)
fs::file_exists("C:\Users\darre\OneDrive\Documents\UICOM Research\LUDB\data\1.avf")
fs::file_exists("C:/Users/darre/OneDrive/Documents/UICOM Research/LUDB/data/1.avf")
find_wfdb_command <- function(.app,
.path = getOption('wfdb_path')) {
cmd <- fs::path(.path, .app)
if (fs::file_exists(cmd)) {
return(cmd)
} else {
warning("Cannot find '", .app, "' in '", .path, "'")
}
}
#' @keywords internal
#' @noRd
annotation_table_to_lines <- function(data) {
# Each annotation file has a string length of 42 characters
# Each annotation `rdann -e` has 4 characters of spaces up front
# When using the `-e` option for rdann, gives an elapsed time
# That assumption leads to spaces before the time starts
# Columns are... n = 6
#		Time
#		Sample
#		Annotation
#		Type
#		Subtype
#		Channel
#		Number
#		Auxillary (7th, ignored)
# The spacing is as such...
# 	[TIME] = 12
# 	[SAMPLE] = 9
# 	[TYPE] = 6
# 	[SUBTYPE] = 5
# 	[CHANNEL] = 5
# 	[NUMBER] = 5
# Each column can get appropriately padded back into lines
v1 <- stringr::str_pad(data[[1]], width = 12, side = "left")
v2 <- stringr::str_pad(data[[2]], width = 9, side = "left")
v3 <- stringr::str_pad(data[[3]], width = 6, side = "left")
v4 <- stringr::str_pad(data[[4]], width = 5, side = "left")
v5 <- stringr::str_pad(data[[5]], width = 5, side = "left")
v6 <- stringr::str_pad(data[[6]], width = 5, side = "left")
# Output will be put back into `wrann` compatible lines
# 	base::sprintf() is 2-3 faster than paste
# 	lines <- paste0(v1, v2, v3, v4, v5, v6)
lines <- sprintf(paste0(rep("%s", 6), collapse = ""), v1, v2, v3, v4, v5, v6)
# Return
lines
}
#' Evaluates a character string and extracts first date and time objects
#' Internally contains different matches for different WFDB formats
#' Requires that string can be broken into components via a space
#' @keywords internal
#' @noRd
parse_date_and_time <- function(x) {
stopifnot('Requires `x` to be a character string' = is.character(x))
# Time
# 	Assumes HH:MM:SS
tm <- stringr::str_extract(x, '\\d\\d:\\d\\d:\\d\\d')
# Dates are more varied
# 	DD/MM/YYYY
dt <- stringr::str_extract(x, '\\d+/\\d+/\\d+')
# Create date time
as.POSIXct(strptime(paste(tm[1], dt[1]), "%H:%M:%S %d/%m/%Y"))
}
read_signal_ds("1.avf")
read_signal_ds <- function(record,
record_dir = ".",
wfdb_path = getOption("wfdb_path"),
begin = 0,
end = NA_integer_,
interval = NA_integer_,
units = "digital",
channels = character(),
...) {
#' @describeIn wfdb_io Specifically reads the signal data from the WFDB binary
#'   format, returning a `signal_table` object for evaluation in the R
#'   environment
#'
#' @export
# Validate:
#		WFDB software command
# 	Current or parent working directory
# 	Directory of the record/WFDB files
# 	Variable definitions
# rdsamp <- find_wfdb_command("rdsamp")
if (fs::dir_exists(record_dir)) {
wd <- fs::path(record_dir)
} else {
wd <- getwd()
}
checkmate::assert_number(begin)
checkmate::assert_number(end, na.ok = TRUE)
checkmate::assert_number(interval, na.ok = TRUE)
checkmate::assert_choice(units, choices = c("digital", "physical"))
# Create all the necessary parameters for rdsamp
#		-f			Start time
#		-l, -t	Interval length OR end time ... one or other, not both
#		-H			High resolution mode for high-sampling frequencies
#		-p			Uses physical units instead of digital
#							Miliseconds/physical (mV) units
#							default is sample interval (index) and A/D units
# 	-P			Capital P gives back higher number of decimal places
#		-s			Select which signals to print out (can duplicate + re-order)
#							Name or Number, separated by spaces
#							Default prints all signals
#		-v			Column headings
#		-X, -c	Output format: either XML or CSV, default = tab (not needed)
cmd <-
paste(rdsamp, '-r', record) |>
{
\(.) {
if (begin != 0) {
paste(., "-f", begin)
} else {
.
}
}
}() |>
{
\(.) {
if (!is.na(interval)) {
paste(., "-l", interval)
} else {
.
}
}
}() |>
{
\(.) {
if (!is.na(end)) {
paste(., "-t", end)
} else {
.
}
}
}() |>
{
\(.) {
if (units == "physical") {
paste(., "-p")
} else {
.
}
}
}() |>
{
\(.) {
if (length(channels) > 0) {
paste(., "-s", paste(channels, collapse = " "))
} else {
.
}
}
}() |>
paste("-v")
# Temporary local/working directory, to reset at end of function
withr::with_dir(new = wd, code = {
dat <- data.table::fread(cmd = cmd)
})
# Return data after cleaning names
names(dat)[1] <- "sample"
signal_table(dat)
}
read_signal_ds("1.avf")
rdsamp <- find_wfdb_command("rdsamp")
rdsamp <- find_wfdb_command("record_dir")
record_Dir
record_dir
help("bin")
ls()
file("1.asv")
test.file = file("1.asv")
read.filename = file("1.asv")
column.names <- readBin(read.filename, character(),  n = 3)
bindata <- readBin(read.filename, integer(),  n = 18)
help(readBin)
help(read.filename)
help("read.filename")
read.filename
bindata <- readBin(read.filename)
bindata <- readBin(read.filename, integer(),  n = 18)
read_signal_ds(1.dat)
read_signal_ds("1.dat)
read_signal_ds("1.dat")
